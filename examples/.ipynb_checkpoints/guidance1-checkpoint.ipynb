{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296dd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# appending a path\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pychop\n",
    "from pychop.chop import Chop\n",
    "from pychop import float_params\n",
    "from time import time\n",
    "from numpy import linalg\n",
    "import jax\n",
    "from pychop import Customs\n",
    "# from pychop.chop import chop\n",
    "# from pychop.quant import quant\n",
    "from time import time\n",
    "from scipy.io import savemat\n",
    "# np.set_printoptions(precision=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8e9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405235  0.40015721  0.97873798 ...  0.92918181  0.22941801\n",
      "   0.41440588]\n",
      " [ 0.30972382 -0.73745619 -1.53691988 ...  0.51687218 -0.03292069\n",
      "   1.29811143]\n",
      " [-0.20211703 -0.833231    1.73360025 ...  0.75309415 -0.58103281\n",
      "  -0.19837974]\n",
      " ...\n",
      " [ 1.07432182  1.188486    0.5092741  ...  0.07053449  0.59975911\n",
      "  -2.41029925]\n",
      " [ 0.32432475 -0.02337844  1.62873399 ... -0.16088168 -1.59772992\n",
      "   1.414703  ]\n",
      " [ 0.63460807  1.38090977  0.54829109 ...  0.30762729 -0.11078251\n",
      "   0.83859307]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X_np = np.random.randn(5000, 5000) # Numpy array\n",
    "X_th = torch.Tensor(X_np) # torch array\n",
    "X_jx = jax.numpy.asarray(X_np)\n",
    "print(X_np)\n",
    "\n",
    "#savemat(\"tests/verify.mat\", {\"X\":X_np})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8962a603-dbb8-4992-924c-4fd7dcbd3ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7641,  0.3097, -0.2021,  2.4700,  0.3300])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_th[0:5, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b51fba",
   "metadata": {},
   "source": [
    "### print unit-roundoff in machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618838ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>xmins</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>p</th>\n",
       "      <th>emins</th>\n",
       "      <th>emin</th>\n",
       "      <th>emax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q43</td>\n",
       "      <td>6.25e-02</td>\n",
       "      <td>1.95e-03</td>\n",
       "      <td>1.56e-02</td>\n",
       "      <td>2.40e+02</td>\n",
       "      <td>4</td>\n",
       "      <td>-9</td>\n",
       "      <td>-6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q52</td>\n",
       "      <td>1.25e-01</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>6.10e-05</td>\n",
       "      <td>5.73e+04</td>\n",
       "      <td>3</td>\n",
       "      <td>-16</td>\n",
       "      <td>-14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>3.91e-03</td>\n",
       "      <td>9.18e-41</td>\n",
       "      <td>1.18e-38</td>\n",
       "      <td>3.39e+38</td>\n",
       "      <td>8</td>\n",
       "      <td>-133</td>\n",
       "      <td>-126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>4.88e-04</td>\n",
       "      <td>5.96e-08</td>\n",
       "      <td>6.10e-05</td>\n",
       "      <td>6.55e+04</td>\n",
       "      <td>11</td>\n",
       "      <td>-24</td>\n",
       "      <td>-14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t</td>\n",
       "      <td>4.88e-04</td>\n",
       "      <td>1.15e-41</td>\n",
       "      <td>1.18e-38</td>\n",
       "      <td>3.40e+38</td>\n",
       "      <td>11</td>\n",
       "      <td>-136</td>\n",
       "      <td>-126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s</td>\n",
       "      <td>5.96e-08</td>\n",
       "      <td>1.40e-45</td>\n",
       "      <td>1.18e-38</td>\n",
       "      <td>3.40e+38</td>\n",
       "      <td>24</td>\n",
       "      <td>-149</td>\n",
       "      <td>-126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d</td>\n",
       "      <td>1.11e-16</td>\n",
       "      <td>4.94e-324</td>\n",
       "      <td>2.23e-308</td>\n",
       "      <td>1.80e+308</td>\n",
       "      <td>53</td>\n",
       "      <td>-1074</td>\n",
       "      <td>-1022</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>q</td>\n",
       "      <td>9.63e-35</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>inf</td>\n",
       "      <td>113</td>\n",
       "      <td>-16494</td>\n",
       "      <td>-16382</td>\n",
       "      <td>16383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                u      xmins       xmin       xmax    p    emins     emin  \\\n",
       "0  q43   6.25e-02   1.95e-03   1.56e-02   2.40e+02    4       -9       -6   \n",
       "1  q52   1.25e-01   1.53e-05   6.10e-05   5.73e+04    3      -16      -14   \n",
       "2    b   3.91e-03   9.18e-41   1.18e-38   3.39e+38    8     -133     -126   \n",
       "3    h   4.88e-04   5.96e-08   6.10e-05   6.55e+04   11      -24      -14   \n",
       "4    t   4.88e-04   1.15e-41   1.18e-38   3.40e+38   11     -136     -126   \n",
       "5    s   5.96e-08   1.40e-45   1.18e-38   3.40e+38   24     -149     -126   \n",
       "6    d   1.11e-16  4.94e-324  2.23e-308  1.80e+308   53    -1074    -1022   \n",
       "7    q   9.63e-35   0.00e+00   0.00e+00        inf  113   -16494   -16382   \n",
       "\n",
       "     emax  \n",
       "0       7  \n",
       "1      15  \n",
       "2     127  \n",
       "3      15  \n",
       "4     127  \n",
       "5     127  \n",
       "6    1023  \n",
       "7   16383  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e72fb9",
   "metadata": {},
   "source": [
    "### set backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9297600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NumPy backend.\n"
     ]
    }
   ],
   "source": [
    "# pychop.backend('torch')\n",
    "pychop.backend('numpy', 1) # print information, NumPy is the default option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417a000",
   "metadata": {},
   "source": [
    "### run chop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ade7038-b100-46ee-8f12-45147d0f2047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 2.426442861557007\n",
      "[ 1.76367188  0.30981445 -0.20214844  2.47070312  0.33007812  0.30200195\n",
      "  0.37133789  0.38720703 -1.93945312  0.56152344]\n"
     ]
    }
   ],
   "source": [
    "pyq_f = Chop('h')\n",
    "st = time()\n",
    "X_bit = pyq_f(X_np)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56faf742-e8cf-4665-bb8a-eaf6f93f43de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.1262867450714111\n",
      "tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301,  0.3020,  0.3713,  0.3872,\n",
      "        -1.9395,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=1)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7def80e-0e97-415d-aad8-cb7c510a422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 0.7792668342590332\n",
      "tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301,  0.3022,  0.3713,  0.3875,\n",
      "        -1.9395,  0.5620])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=2)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504c13ad-7b33-44a0-aa02-b043ad4ee304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 0.74953293800354\n",
      "tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298,  0.3020,  0.3711,  0.3872,\n",
      "        -1.9404,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=3)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e283b85-043e-46d6-b0f1-f442255681fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 0.808826208114624\n",
      "tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298,  0.3020,  0.3711,  0.3872,\n",
      "        -1.9395,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=4)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a3a9234-2b01-44bc-adf7-2a8daf6adc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "145f815f-c59c-4c88-8f08-ea2ea49c01fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input values:       tensor([ 1.7641,  0.3097, -0.2021,  2.4700,  0.3300])\n",
      "PyTorch FP16:       tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n",
      "\n",
      "\n",
      "nearest     ,  Correct:    tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n",
      "nearest     ,  Emulated: tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n",
      "up          ,  Correct:    tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301])\n",
      "up          ,  Emulated: tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301])\n",
      "down        ,  Correct:    tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298])\n",
      "down        ,  Emulated: tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298])\n",
      "towards_zero,  Correct:    tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298])\n",
      "towards_zero,  Emulated: tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298])\n"
     ]
    }
   ],
   "source": [
    "from pychop.lightchop import LightChop # only can be imported after using torch backend\n",
    "\n",
    "\n",
    "values = torch.tensor([1.7641, 0.3097, -0.2021, 2.4700, 0.3300])\n",
    "\n",
    "# half precision simulator (5 exponent bits, 10 mantissa bits)\n",
    "fp16_sim = LightChop(5, 10)\n",
    "\n",
    "rounding_modes = [\"nearest\", \"up\", \"down\", \"towards_zero\", \n",
    "                 \"stochastic_equal\", \"stochastic_proportional\"]\n",
    "\n",
    "# Compare with PyTorch's native FP16\n",
    "fp16_native = values.to(dtype=torch.float16).to(dtype=torch.float32)\n",
    "\n",
    "print(\"Input values:      \", values)\n",
    "print(\"PyTorch FP16:      \", fp16_native)\n",
    "print()\n",
    "\n",
    "print()\n",
    "rounding_modes_num = [1, 2, 3, 4, \"stochastic_equal\", \"stochastic_proportional\"]\n",
    "\n",
    "for mode in rounding_modes_num[:4]:\n",
    "    pyq_f = Chop('h', rmode=mode)\n",
    "    groud_truth = pyq_f(values)\n",
    "    emulated = fp16_sim.quantize(values, rounding_modes[mode-1])\n",
    "    assert np.array_equal(emulated, groud_truth), print(\"error rmode 3\")\n",
    "    \n",
    "    print(f\"{rounding_modes[mode-1]:12}, \", \"Correct:\", f\"   {emulated}\")\n",
    "    print(f\"{rounding_modes[mode-1]:12}, \", \"Emulated:\", f\"{groud_truth}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4a1316f-6338-4064-bbeb-c0a247fa9702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original values: tensor([ 0.1000,  0.3000,  1.7000,  3.9000, -2.5000])\n",
      "nearest: tensor([ 0.1001,  0.3008,  1.7031,  3.9062, -2.5000])\n",
      "up: tensor([ 0.1001,  0.3008,  1.7031,  3.9062, -2.5000])\n",
      "down: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n",
      "towards_zero: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n",
      "stochastic_equal: tensor([ 0.0996,  0.3008,  1.6953,  3.8906, -2.5000])\n",
      "stochastic_proportional: tensor([ 0.1001,  0.3008,  1.6953,  3.9062, -2.5000])\n"
     ]
    }
   ],
   "source": [
    "from pychop.layers import QuantizedLayer\n",
    "\n",
    "formats = {\n",
    "    \"fp32\": (8, 23),    # Standard IEEE 754 float32\n",
    "    \"fp16\": (5, 10),    # Standard IEEE 754 float16\n",
    "    \"bf16\": (8, 7),     # bfloat16\n",
    "    \"fp8\": (5, 2),      # Example 8-bit float\n",
    "}\n",
    "\n",
    "# Test different rounding modes\n",
    "rounding_modes = [\n",
    "    \"nearest\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"towards_zero\",\n",
    "    \"stochastic_equal\",\n",
    "    \"stochastic_proportional\"\n",
    "]\n",
    "\n",
    "# Create a sample tensor\n",
    "x = torch.tensor([0.1, 0.3, 1.7, 3.9, -2.5])\n",
    "\n",
    "# Test quantization\n",
    "mp = LightChop(*formats[\"bf16\"])\n",
    "\n",
    "print(\"Original values:\", x)\n",
    "for mode in rounding_modes:\n",
    "    result = mp.quantize(x, mode)\n",
    "    print(f\"{mode}:\", result)\n",
    "\n",
    "# Test with a layer\n",
    "layer = QuantizedLayer(*formats[\"bf16\"], rmode=\"nearest\")\n",
    "input_tensor = torch.randn(3, 4)\n",
    "output = layer(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c5695-d12d-4c8f-9ae8-32762b70f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=1)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1771-a080-4386-bfd5-0c86bd09db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=2)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37848fd-10fc-4789-b1cb-8e1e77ec315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=3)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db74eb8-dd68-4673-8b63-e55e426081ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=4)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b59fd0-ed01-4ac7-98c2-0741e84f032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('jax', 1) # print information\n",
    "pyq_f = Chop('h')\n",
    "st = time()\n",
    "X_bit = pyq_f(X_jx)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57b1a7c5-d1c8-4850-8dc4-a1af7b1417a3",
   "metadata": {},
   "source": [
    "pychop.backend('torch')\n",
    "pyq_f = chop('h', device='cuda')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_gpu = X_th.to(device)\n",
    "pyq_f(X_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c7504-4b05-42e0-9a1c-2157da6a8d37",
   "metadata": {},
   "source": [
    "### Custom precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79af559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pychop.backend('torch')\n",
    "pychop.backend('numpy', 1) # print information, NumPy is the default option.\n",
    "ct1 = Customs(emax=15, t=11) # half precision,  t is the number of bits in the significand \n",
    "                             # (including the hidden bit) and emax is the maximum value of the exponent\n",
    "\n",
    "pyq_f = Chop(customs=ct1, rmode=3) \n",
    "X_bit = pyq_f(X_np)\n",
    "print(X_bit[:10, 0])\n",
    "\n",
    "ct2 = Customs(exp_bits=5, sig_bits=10) # half precision (5 exponent bits, 10+1 significand bits, 1 is implicit bits)\n",
    "pyq_f = Chop(customs=ct2, rmode=3)\n",
    "X_bit = pyq_f(X_np)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4e069-5df2-436d-9422-e0ce95983f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = Customs(7, 4) # q43 precision,  t is the number of bits in the significand \n",
    "                             # (including the hidden bit) and emax is the maximum value of the exponent\n",
    "\n",
    "pyq_f = Chop(customs=ct1, rmode=3) \n",
    "X_bit = pyq_f(X_np)\n",
    "print(X_bit[:10, 0])\n",
    "\n",
    "ct2 = Customs(exp_bits=4, sig_bits=3) # q43 precision (4 exponent bits, 3+1 significand bits, 1 is implicit bits)\n",
    "pyq_f = Chop(customs=ct2, rmode=3)\n",
    "X_bit = pyq_f(X_np)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ecc758",
   "metadata": {},
   "source": [
    "### integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29813b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('numpy')\n",
    "pyq_f = pychop.quant(bits=8)\n",
    "X_q = pyq_f(X_np)\n",
    "X_inv = pyq_f.dequant(X_q)\n",
    "linalg.norm(X_inv - X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef762b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('torch')\n",
    "pyq_f = pychop.quant(bits=8)\n",
    "X_q = pyq_f(X_th)\n",
    "X_inv = pyq_f.dequant(X_q)\n",
    "linalg.norm(X_inv - X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea235d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pychop.backend('jax')\n",
    "pyq_f = pychop.quant(bits=8)\n",
    "X_q = pyq_f(X_jx)\n",
    "X_inv = pyq_f.dequant(X_q)\n",
    "linalg.norm(X_inv - X_jx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151a103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00497bc7",
   "metadata": {},
   "source": [
    "### fixed point quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2099b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('numpy')\n",
    "from pychop import Chopf\n",
    "\n",
    "pyq_f = Chopf(ibits=4, fbits=4)\n",
    "\n",
    "pyq_f(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a320530",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('torch')\n",
    "pyq_f = Chopf() # default: ibits=4, fbits=4,\n",
    "pyq_f(X_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "pychop.backend('jax')\n",
    "pyq_f = Chopf()\n",
    "pyq_f(X_jx)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b02be34-c7b5-462c-92b4-f977e746ad53",
   "metadata": {},
   "source": [
    "from pychop.bitchop import bitchop\n",
    "pychop.backend('numpy')\n",
    "\n",
    "pyq_f = bitchop(exp_bits=5, sig_bits=10, rmode=1, subnormal=True, random_state=42, device=\"cpu\", verbose=0)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_np)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31030621-0cd6-4a07-8376-1e1d9e3ebd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf31fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05eca45-ff22-4368-a68a-8fd4c6728f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b466728-0bc8-4d2f-b6f0-b45b6a13e996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
