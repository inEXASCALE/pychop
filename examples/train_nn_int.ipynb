{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8361ea-4665-44ed-8526-617e1ded6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# appending a path\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pychop\n",
    "from pychop import Chopi\n",
    "pychop.backend('torch')\n",
    "\n",
    "class QuantizedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantizedNet, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1d = nn.Conv1d(1, 16, 3, padding=1)\n",
    "        self.conv2d = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv3d = nn.Conv3d(1, 16, 3, padding=1)\n",
    "\n",
    "        self.wquant_conv1d = Chopi(8, symmetric=True, per_channel=True, channel_dim=0)\n",
    "        self.wquant_conv2d = Chopi(8, symmetric=True, per_channel=True, channel_dim=0)\n",
    "        self.wquant_conv3d = Chopi(8, symmetric=True, per_channel=True, channel_dim=0)\n",
    "\n",
    "        # Recurrent Layers\n",
    "        self.lstm = nn.LSTM(16, 32, batch_first=True)\n",
    "        self.gru = nn.GRU(32, 16, batch_first=True)\n",
    "\n",
    "        self.wquant_lstm_ih = Chopi(8, symmetric=True, per_channel=True, channel_dim=0)\n",
    "        self.wquant_lstm_hh = Chopi(8, symmetric=True, per_channel=True, channel_dim=0)\n",
    "        self.wquant_gru_ih = Chopi(8, symmetric=True, per_channel=True, channel_dim=0)\n",
    "        self.wquant_gru_hh = Chopi(8, symmetric=True, per_channel=True, channel_dim=0)\n",
    "\n",
    "        # BatchNorm, Pooling, and Linear\n",
    "        self.bn2d = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(16 * 14 * 14, 10)  # 14x14 after pooling\n",
    "        self.wquant_fc = Chopi(8, symmetric=True, per_channel=True, channel_dim=0)\n",
    "\n",
    "        # Activation Chopis\n",
    "        self.aquant_conv1d = Chopi(8, symmetric=False, per_channel=True, channel_dim=1)\n",
    "        self.aquant_conv2d = Chopi(8, symmetric=False, per_channel=True, channel_dim=1)\n",
    "        self.aquant_conv3d = Chopi(8, symmetric=False, per_channel=True, channel_dim=1)\n",
    "        self.aquant_lstm = Chopi(8, symmetric=False, per_channel=True, channel_dim=2)  # dim 2 for [batch, seq, feat]\n",
    "        self.aquant_gru = Chopi(8, symmetric=False, per_channel=True, channel_dim=2)\n",
    "        self.aquant_fc = Chopi(8, symmetric=False)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x_1d, x_2d, x_3d, x_seq, training=True):\n",
    "        # Conv1d\n",
    "        w1d = self.wquant_conv1d(self.conv1d.weight, training=training)\n",
    "\n",
    "        x_1d = F.conv1d(x_1d, w1d, self.conv1d.bias, padding=1)\n",
    "        x_1d = self.aquant_conv1d(x_1d, training=training)\n",
    "        x_1d = self.relu(x_1d)\n",
    "\n",
    "        # Conv2d\n",
    "        w2d = self.wquant_conv2d(self.conv2d.weight, training=training)\n",
    "        x_2d = F.conv2d(x_2d, w2d, self.conv2d.bias, padding=1)\n",
    "        x_2d = self.bn2d(x_2d)\n",
    "        x_2d = self.aquant_conv2d(x_2d, training=training)\n",
    "        x_2d = self.relu(x_2d)\n",
    "        x_2d = self.pool(x_2d)  # [2, 16, 14, 14]\n",
    "        x_2d = x_2d.view(x_2d.size(0), -1)  # [2, 16*14*14]\n",
    "\n",
    "        # Conv3d\n",
    "        w3d = self.wquant_conv3d(self.conv3d.weight, training=training)\n",
    "        x_3d = F.conv3d(x_3d, w3d, self.conv3d.bias, padding=1)\n",
    "        x_3d = self.aquant_conv3d(x_3d, training=training)\n",
    "        x_3d = self.relu(x_3d)\n",
    "\n",
    "        # RNN (LSTM + GRU)\n",
    "        # Note: PyTorch RNNs use fused ops, so we quantize weights but apply them manually is complex.\n",
    "        # For simplicity, we quantize inputs/outputs here; true integer RNNs need custom ops.\n",
    "        w_lstm_ih = self.wquant_lstm_ih(self.lstm.weight_ih_l0, training=training)\n",
    "        w_lstm_hh = self.wquant_lstm_hh(self.lstm.weight_hh_l0, training=training)\n",
    "        x_seq, _ = self.lstm(x_seq)  # Fused op, weights not directly applied here\n",
    "        x_seq = self.aquant_lstm(x_seq, training=training)\n",
    "        w_gru_ih = self.wquant_gru_ih(self.gru.weight_ih_l0, training=training)\n",
    "        w_gru_hh = self.wquant_gru_hh(self.gru.weight_hh_l0, training=training)\n",
    "        x_seq, _ = self.gru(x_seq)\n",
    "        x_seq = self.aquant_gru(x_seq, training=training)\n",
    "        x_seq = x_seq[:, -1, :]  # Last timestep\n",
    "\n",
    "        # Linear\n",
    "        w_fc = self.wquant_fc(self.fc.weight, training=training)\n",
    "        x_2d = F.linear(x_2d, w_fc, self.fc.bias)  # [2, 3136] * [3136, 10]\n",
    "        x_2d = self.aquant_fc(x_2d, training=training)\n",
    "\n",
    "        return x_1d, x_2d, x_3d, x_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1c08d6-9908-44b8-91df-1a268e3948fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training outputs:\n",
      "Conv1d: torch.Size([2, 16, 64]) tensor([0.0862, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Conv2d+FC: torch.Size([2, 10]) tensor([ 1.8073, -0.0506, -0.1454,  0.5371,  1.0490])\n",
      "Conv3d: torch.Size([2, 16, 16, 16, 16]) tensor([0.6106, 0.3408, 0.4564, 1.0732, 0.1095])\n",
      "LSTM+GRU: torch.Size([2, 16]) tensor([ 0.1751,  0.0754, -0.1278, -0.0274, -0.1226])\n",
      "\n",
      "Inference outputs (INT8):\n",
      "Conv1d: torch.Size([2, 16, 64]) tensor([72., 51., 56., 65., 53.])\n",
      "Conv2d+FC: torch.Size([2, 10]) tensor([127.,  44.,  26.,  27.,  86.])\n",
      "Conv3d: torch.Size([2, 16, 16, 16, 16]) tensor([[76., 69., 72., 88., 63., 61., 54., 70., 59., 62., 55., 60., 59., 50.,\n",
      "         70., 74.],\n",
      "        [55., 46., 81., 78., 70., 70., 80., 54., 55., 79., 81., 65., 57., 51.,\n",
      "         77., 68.],\n",
      "        [66., 69., 55., 78., 81., 77., 50., 77., 67., 72., 59., 84., 43., 56.,\n",
      "         55., 65.],\n",
      "        [73., 68., 76., 60., 60., 82., 55., 40., 51., 70., 74., 80., 65., 70.,\n",
      "         51., 70.],\n",
      "        [64., 74., 90., 58., 60., 58., 61., 59., 60., 43., 69., 77., 61., 85.,\n",
      "         64., 68.]])\n",
      "LSTM+GRU: torch.Size([2, 16]) tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test():\n",
    "    model = QuantizedNet()\n",
    "    model.train()\n",
    "\n",
    "    x_1d = torch.randn(2, 1, 64)  # [batch, channels, length]\n",
    "    x_2d = torch.randn(2, 1, 28, 28)  # [batch, channels, height, width]\n",
    "    x_3d = torch.randn(2, 1, 16, 16, 16)  # [batch, channels, depth, height, width]\n",
    "    x_seq = torch.randn(2, 10, 16)  # [batch, seq_len, features]\n",
    "\n",
    "    # Training mode\n",
    "    out_1d, out_2d, out_3d, out_seq = model(x_1d, x_2d, x_3d, x_seq, training=True)\n",
    "    print(\"Training outputs:\")\n",
    "    print(\"Conv1d:\", out_1d.shape, out_1d[0, 0, :5])\n",
    "    print(\"Conv2d+FC:\", out_2d.shape, out_2d[0, :5])\n",
    "    print(\"Conv3d:\", out_3d.shape, out_3d[0, 0, 0, 0, :5])\n",
    "    print(\"LSTM+GRU:\", out_seq.shape, out_seq[0, :5])\n",
    "\n",
    "    # Inference mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out_1d, out_2d, out_3d, out_seq = model(x_1d, x_2d, x_3d, x_seq, training=False)\n",
    "        print(\"\\nInference outputs (INT8):\")\n",
    "        print(\"Conv1d:\", out_1d.shape, out_1d[0, 0, :5])\n",
    "        print(\"Conv2d+FC:\", out_2d.shape, out_2d[0, :5])\n",
    "        print(\"Conv3d:\", out_3d.shape, out_3d[0, 0, 0, :5])\n",
    "        print(\"LSTM+GRU:\", out_seq.shape, out_seq[0, :5])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea680bb3-37f8-4830-9b4c-b8f85c5bfc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
