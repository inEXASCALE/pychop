{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296dd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# appending a path\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pychop\n",
    "from pychop.chop import Chop\n",
    "from pychop import float_params\n",
    "from time import time\n",
    "from numpy import linalg\n",
    "import jax\n",
    "from pychop import Customs\n",
    "# from pychop.chop import chop\n",
    "# from pychop.quant import quant\n",
    "from time import time\n",
    "# from scipy.io import savemat\n",
    "# np.set_printoptions(precision=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8e9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405235  0.40015721  0.97873798 ...  0.92918181  0.22941801\n",
      "   0.41440588]\n",
      " [ 0.30972382 -0.73745619 -1.53691988 ...  0.51687218 -0.03292069\n",
      "   1.29811143]\n",
      " [-0.20211703 -0.833231    1.73360025 ...  0.75309415 -0.58103281\n",
      "  -0.19837974]\n",
      " ...\n",
      " [ 1.07432182  1.188486    0.5092741  ...  0.07053449  0.59975911\n",
      "  -2.41029925]\n",
      " [ 0.32432475 -0.02337844  1.62873399 ... -0.16088168 -1.59772992\n",
      "   1.414703  ]\n",
      " [ 0.63460807  1.38090977  0.54829109 ...  0.30762729 -0.11078251\n",
      "   0.83859307]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X_np = np.random.randn(5000, 5000) # Numpy array\n",
    "X_th = torch.Tensor(X_np) # torch array\n",
    "X_jx = jax.numpy.asarray(X_np)\n",
    "print(X_np)\n",
    "\n",
    "#savemat(\"tests/verify.mat\", {\"X\":X_np})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8962a603-dbb8-4992-924c-4fd7dcbd3ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7641,  0.3097, -0.2021,  2.4700,  0.3300])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_th[0:5, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b51fba",
   "metadata": {},
   "source": [
    "### print unit-roundoff in machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618838ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>xmins</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>p</th>\n",
       "      <th>emins</th>\n",
       "      <th>emin</th>\n",
       "      <th>emax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q43</td>\n",
       "      <td>6.25e-02</td>\n",
       "      <td>1.95e-03</td>\n",
       "      <td>1.56e-02</td>\n",
       "      <td>2.40e+02</td>\n",
       "      <td>4</td>\n",
       "      <td>-9</td>\n",
       "      <td>-6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q52</td>\n",
       "      <td>1.25e-01</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>6.10e-05</td>\n",
       "      <td>5.73e+04</td>\n",
       "      <td>3</td>\n",
       "      <td>-16</td>\n",
       "      <td>-14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>3.91e-03</td>\n",
       "      <td>9.18e-41</td>\n",
       "      <td>1.18e-38</td>\n",
       "      <td>3.39e+38</td>\n",
       "      <td>8</td>\n",
       "      <td>-133</td>\n",
       "      <td>-126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>4.88e-04</td>\n",
       "      <td>5.96e-08</td>\n",
       "      <td>6.10e-05</td>\n",
       "      <td>6.55e+04</td>\n",
       "      <td>11</td>\n",
       "      <td>-24</td>\n",
       "      <td>-14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t</td>\n",
       "      <td>4.88e-04</td>\n",
       "      <td>1.15e-41</td>\n",
       "      <td>1.18e-38</td>\n",
       "      <td>3.40e+38</td>\n",
       "      <td>11</td>\n",
       "      <td>-136</td>\n",
       "      <td>-126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s</td>\n",
       "      <td>5.96e-08</td>\n",
       "      <td>1.40e-45</td>\n",
       "      <td>1.18e-38</td>\n",
       "      <td>3.40e+38</td>\n",
       "      <td>24</td>\n",
       "      <td>-149</td>\n",
       "      <td>-126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d</td>\n",
       "      <td>1.11e-16</td>\n",
       "      <td>4.94e-324</td>\n",
       "      <td>2.23e-308</td>\n",
       "      <td>1.80e+308</td>\n",
       "      <td>53</td>\n",
       "      <td>-1074</td>\n",
       "      <td>-1022</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>q</td>\n",
       "      <td>9.63e-35</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>inf</td>\n",
       "      <td>113</td>\n",
       "      <td>-16494</td>\n",
       "      <td>-16382</td>\n",
       "      <td>16383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                u      xmins       xmin       xmax    p    emins     emin  \\\n",
       "0  q43   6.25e-02   1.95e-03   1.56e-02   2.40e+02    4       -9       -6   \n",
       "1  q52   1.25e-01   1.53e-05   6.10e-05   5.73e+04    3      -16      -14   \n",
       "2    b   3.91e-03   9.18e-41   1.18e-38   3.39e+38    8     -133     -126   \n",
       "3    h   4.88e-04   5.96e-08   6.10e-05   6.55e+04   11      -24      -14   \n",
       "4    t   4.88e-04   1.15e-41   1.18e-38   3.40e+38   11     -136     -126   \n",
       "5    s   5.96e-08   1.40e-45   1.18e-38   3.40e+38   24     -149     -126   \n",
       "6    d   1.11e-16  4.94e-324  2.23e-308  1.80e+308   53    -1074    -1022   \n",
       "7    q   9.63e-35   0.00e+00   0.00e+00        inf  113   -16494   -16382   \n",
       "\n",
       "     emax  \n",
       "0       7  \n",
       "1      15  \n",
       "2     127  \n",
       "3      15  \n",
       "4     127  \n",
       "5     127  \n",
       "6    1023  \n",
       "7   16383  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e72fb9",
   "metadata": {},
   "source": [
    "### set backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9297600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NumPy backend.\n"
     ]
    }
   ],
   "source": [
    "# pychop.backend('torch')\n",
    "pychop.backend('numpy', 1) # print information, NumPy is the default option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417a000",
   "metadata": {},
   "source": [
    "### run chop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ade7038-b100-46ee-8f12-45147d0f2047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 2.2011141777038574\n",
      "[ 1.76367188  0.30981445 -0.20214844  2.47070312  0.33007812  0.30200195\n",
      "  0.37133789  0.38720703 -1.93945312  0.56152344]\n"
     ]
    }
   ],
   "source": [
    "pyq_f = Chop('h')\n",
    "st = time()\n",
    "X_bit = pyq_f(X_np)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56faf742-e8cf-4665-bb8a-eaf6f93f43de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 2.7147562503814697\n",
      "tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301,  0.3020,  0.3713,  0.3872,\n",
      "        -1.9395,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=1)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7def80e-0e97-415d-aad8-cb7c510a422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.5571949481964111\n",
      "tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301,  0.3022,  0.3713,  0.3875,\n",
      "        -1.9395,  0.5620])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=2)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504c13ad-7b33-44a0-aa02-b043ad4ee304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.5467493534088135\n",
      "tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298,  0.3020,  0.3711,  0.3872,\n",
      "        -1.9404,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=3)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e283b85-043e-46d6-b0f1-f442255681fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.6779279708862305\n",
      "tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298,  0.3020,  0.3711,  0.3872,\n",
      "        -1.9395,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=4)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a3a9234-2b01-44bc-adf7-2a8daf6adc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "145f815f-c59c-4c88-8f08-ea2ea49c01fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input values:       tensor([ 1.7641,  0.3097, -0.2021,  2.4700,  0.3300])\n",
      "PyTorch FP16:       tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n",
      "\n",
      "\n",
      "nearest     ,  Correct:    tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n",
      "nearest     ,  Emulated: tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n",
      "up          ,  Correct:    tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301])\n",
      "up          ,  Emulated: tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301])\n",
      "down        ,  Correct:    tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298])\n",
      "down        ,  Emulated: tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298])\n",
      "towards_zero,  Correct:    tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298])\n",
      "towards_zero,  Emulated: tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298])\n"
     ]
    }
   ],
   "source": [
    "from pychop.lightchop import LightChop # only can be imported after using torch backend\n",
    "\n",
    "\n",
    "values = torch.tensor([1.7641, 0.3097, -0.2021, 2.4700, 0.3300])\n",
    "\n",
    "\n",
    "rounding_modes = [\"nearest\", \"up\", \"down\", \"towards_zero\", \n",
    "                 \"stochastic_equal\", \"stochastic_proportional\"]\n",
    "\n",
    "# Compare with PyTorch's native FP16\n",
    "fp16_native = values.to(dtype=torch.float16).to(dtype=torch.float32)\n",
    "\n",
    "print(\"Input values:      \", values)\n",
    "print(\"PyTorch FP16:      \", fp16_native)\n",
    "print()\n",
    "\n",
    "print()\n",
    "rounding_modes_num = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "for mode in rounding_modes_num[:4]:\n",
    "    pyq_f = Chop('h', rmode=mode)\n",
    "    groud_truth = pyq_f(values)\n",
    "    \n",
    "    # half precision simulator (5 exponent bits, 10 mantissa bits)\n",
    "    fp16_sim = LightChop(5, 10, rmode=mode)\n",
    "    emulated = fp16_sim.quantize(values)\n",
    "    assert np.array_equal(emulated, groud_truth), print(\"error rmode 3\")\n",
    "    \n",
    "    print(f\"{rounding_modes[mode-1]:12}, \", \"Correct:\", f\"   {emulated}\")\n",
    "    print(f\"{rounding_modes[mode-1]:12}, \", \"Emulated:\", f\"{groud_truth}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a1316f-6338-4064-bbeb-c0a247fa9702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original values: tensor([ 0.1000,  0.3000,  1.7000,  3.9000, -2.5000])\n",
      "nearest: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n",
      "plus_inf: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n",
      "minus_inf: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n",
      "towards_zero: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n",
      "stoc_equal: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n",
      "stoc_prop: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n"
     ]
    }
   ],
   "source": [
    "from pychop.layers import QuantizedLayer\n",
    "\n",
    "formats = {\n",
    "    \"fp32\": (8, 23),    # Standard IEEE 754 float32\n",
    "    \"fp16\": (5, 10),    # Standard IEEE 754 float16\n",
    "    \"bf16\": (8, 7),     # bfloat16\n",
    "    \"fp8\": (5, 2),      # Example 8-bit float\n",
    "}\n",
    "\n",
    "# Test different rounding modes\n",
    "rounding_modes = [\n",
    "    \"nearest\",\n",
    "    \"plus_inf\",\n",
    "    \"minus_inf\",\n",
    "    \"towards_zero\",\n",
    "    \"stoc_equal\",\n",
    "    \"stoc_prop\"\n",
    "]\n",
    "# Create a sample tensor\n",
    "x = torch.tensor([0.1, 0.3, 1.7, 3.9, -2.5])\n",
    "\n",
    "# Test quantization\n",
    "mp = LightChop(*formats[\"bf16\"], mode)\n",
    "\n",
    "print(\"Original values:\", x)\n",
    "for mode in rounding_modes:\n",
    "    result = mp.quantize(x)\n",
    "    print(f\"{mode}:\", result)\n",
    "\n",
    "# Test with a layer\n",
    "layer = QuantizedLayer(*formats[\"bf16\"])\n",
    "input_tensor = torch.randn(3, 4)\n",
    "output = layer(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b33c5695-d12d-4c8f-9ae8-32762b70f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.7165188789367676\n",
      "tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=1)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90d1771-a080-4386-bfd5-0c86bd09db3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.4376509189605713\n",
      "tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=2)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c37848fd-10fc-4789-b1cb-8e1e77ec315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.4878880977630615\n",
      "tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=3)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4db74eb8-dd68-4673-8b63-e55e426081ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.7052178382873535\n",
      "tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = Chop('h', rmode=4)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01b59fd0-ed01-4ac7-98c2-0741e84f032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load JAX backend.\n",
      "runtime: 12.719720125198364\n",
      "[[ 1.7636719   0.40014648  0.9785156  ...  0.9291992   0.22937012\n",
      "   0.41430664]\n",
      " [ 0.30981445 -0.7373047  -1.5371094  ...  0.51708984 -0.03292847\n",
      "   1.2978516 ]\n",
      " [-0.20214844 -0.8330078   1.7333984  ...  0.7529297  -0.5810547\n",
      "  -0.19836426]\n",
      " ...\n",
      " [ 1.0742188   1.1884766   0.50927734 ...  0.07055664  0.5996094\n",
      "  -2.4101562 ]\n",
      " [ 0.32421875 -0.02337646  1.6289062  ... -0.16088867 -1.5976562\n",
      "   1.4150391 ]\n",
      " [ 0.6347656   1.3808594   0.54833984 ...  0.3076172  -0.11077881\n",
      "   0.8383789 ]]\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('jax', 1) # print information\n",
    "pyq_f = Chop('h')\n",
    "st = time()\n",
    "X_bit = pyq_f(X_jx)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57b1a7c5-d1c8-4850-8dc4-a1af7b1417a3",
   "metadata": {},
   "source": [
    "pychop.backend('torch')\n",
    "pyq_f = chop('h', device='cuda')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_gpu = X_th.to(device)\n",
    "pyq_f(X_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c7504-4b05-42e0-9a1c-2157da6a8d37",
   "metadata": {},
   "source": [
    "### Custom precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f79af559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NumPy backend.\n",
      "[ 1.76367188  0.30957031 -0.20214844  2.46875     0.32983398  0.30200195\n",
      "  0.37109375  0.38720703 -1.94042969  0.56152344]\n",
      "[ 1.76367188  0.30957031 -0.20214844  2.46875     0.32983398  0.30200195\n",
      "  0.37109375  0.38720703 -1.94042969  0.56152344]\n"
     ]
    }
   ],
   "source": [
    "# pychop.backend('torch')\n",
    "pychop.backend('numpy', 1) # print information, NumPy is the default option.\n",
    "ct1 = Customs(emax=15, t=11) # half precision,  t is the number of bits in the significand \n",
    "                             # (including the hidden bit) and emax is the maximum value of the exponent\n",
    "\n",
    "pyq_f = Chop(customs=ct1, rmode=3) \n",
    "X_bit = pyq_f(X_np)\n",
    "print(X_bit[:10, 0])\n",
    "\n",
    "ct2 = Customs(exp_bits=5, sig_bits=10) # half precision (5 exponent bits, 10+1 significand bits, 1 is implicit bits)\n",
    "pyq_f = Chop(customs=ct2, rmode=3)\n",
    "X_bit = pyq_f(X_np)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e4e069-5df2-436d-9422-e0ce95983f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.75      0.28125  -0.203125  2.25      0.3125    0.28125   0.34375\n",
      "  0.375    -2.        0.5     ]\n",
      "[ 1.75      0.28125  -0.203125  2.25      0.3125    0.28125   0.34375\n",
      "  0.375    -2.        0.5     ]\n"
     ]
    }
   ],
   "source": [
    "ct1 = Customs(7, 4) # q43 precision,  t is the number of bits in the significand \n",
    "                             # (including the hidden bit) and emax is the maximum value of the exponent\n",
    "\n",
    "pyq_f = Chop(customs=ct1, rmode=3) \n",
    "X_bit = pyq_f(X_np)\n",
    "print(X_bit[:10, 0])\n",
    "\n",
    "ct2 = Customs(exp_bits=4, sig_bits=3) # q43 precision (4 exponent bits, 3+1 significand bits, 1 is implicit bits)\n",
    "pyq_f = Chop(customs=ct2, rmode=3)\n",
    "X_bit = pyq_f(X_np)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ecc758",
   "metadata": {},
   "source": [
    "### integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c29813b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48872269380767824"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('numpy')\n",
    "pyq_f = pychop.Chopi(16)\n",
    "X_q = pyq_f.quantize(X_np)\n",
    "X_inv = pyq_f.dequantize(X_q)\n",
    "linalg.norm(X_inv - X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef762b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48856017"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('torch')\n",
    "pyq_f = pychop.Chopi(num_bits=16)\n",
    "X_q = pyq_f.quantize(X_th)\n",
    "X_inv = pyq_f.dequantize(X_q)\n",
    "linalg.norm(X_inv - X_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "818514fb-2a9e-4e9e-84f4-11634b3fe443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea235d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenxinye/pychop/examples/../pychop/jx/integer.py:44: UserWarning: Current int type does not support this bitwidth, use int64 to simulate.\n",
      "  warnings.warn(\"Current int type does not support this bitwidth, use int64 to simulate.\")\n",
      "/opt/anaconda3/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:122: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4995.702"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('jax')\n",
    "pyq_f = pychop.Chopi(num_bits=2)\n",
    "X_q = pyq_f.quantize(X_jx)\n",
    "X_inv = pyq_f.dequantize(X_q)\n",
    "linalg.norm(X_inv - X_jx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151a103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00497bc7",
   "metadata": {},
   "source": [
    "### fixed point quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2099b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.75  ,  0.375 ,  1.    , ...,  0.9375,  0.25  ,  0.4375],\n",
       "       [ 0.3125, -0.75  , -1.5625, ...,  0.5   , -0.0625,  1.3125],\n",
       "       [-0.1875, -0.8125,  1.75  , ...,  0.75  , -0.5625, -0.1875],\n",
       "       ...,\n",
       "       [ 1.0625,  1.1875,  0.5   , ...,  0.0625,  0.625 , -2.4375],\n",
       "       [ 0.3125, -0.    ,  1.625 , ..., -0.1875, -1.625 ,  1.4375],\n",
       "       [ 0.625 ,  1.375 ,  0.5625, ...,  0.3125, -0.125 ,  0.8125]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('numpy')\n",
    "from pychop import Chopf\n",
    "\n",
    "pyq_f = Chopf(ibits=4, fbits=4)\n",
    "\n",
    "pyq_f(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a320530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7500,  0.3750,  1.0000,  ...,  0.9375,  0.2500,  0.4375],\n",
       "        [ 0.3125, -0.7500, -1.5625,  ...,  0.5000, -0.0625,  1.3125],\n",
       "        [-0.1875, -0.8125,  1.7500,  ...,  0.7500, -0.5625, -0.1875],\n",
       "        ...,\n",
       "        [ 1.0625,  1.1875,  0.5000,  ...,  0.0625,  0.6250, -2.4375],\n",
       "        [ 0.3125, -0.0000,  1.6250,  ..., -0.1875, -1.6250,  1.4375],\n",
       "        [ 0.6250,  1.3750,  0.5625,  ...,  0.3125, -0.1250,  0.8125]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('torch')\n",
    "pyq_f = Chopf() # default: ibits=4, fbits=4,\n",
    "pyq_f(X_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f58d8820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.75  ,  0.375 ,  1.    , ...,  0.9375,  0.25  ,  0.4375],\n",
       "       [ 0.3125, -0.75  , -1.5625, ...,  0.5   , -0.0625,  1.3125],\n",
       "       [-0.1875, -0.8125,  1.75  , ...,  0.75  , -0.5625, -0.1875],\n",
       "       ...,\n",
       "       [ 1.0625,  1.1875,  0.5   , ...,  0.0625,  0.625 , -2.4375],\n",
       "       [ 0.3125, -0.    ,  1.625 , ..., -0.1875, -1.625 ,  1.4375],\n",
       "       [ 0.625 ,  1.375 ,  0.5625, ...,  0.3125, -0.125 ,  0.8125]],      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('jax')\n",
    "pyq_f = Chopf()\n",
    "pyq_f(X_jx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "016e69ce-68c4-48b6-b967-52dd78064582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyq_f.rmode"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b02be34-c7b5-462c-92b4-f977e746ad53",
   "metadata": {},
   "source": [
    "from pychop.bitchop import bitchop\n",
    "pychop.backend('numpy')\n",
    "\n",
    "pyq_f = bitchop(exp_bits=5, sig_bits=10, rmode=1, subnormal=True, random_state=42, device=\"cpu\", verbose=0)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_np)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31030621-0cd6-4a07-8376-1e1d9e3ebd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1adc4597-adfa-4df2-8d2e-695ab80d8a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405235  0.40015721  0.97873798 ... -0.51423397 -1.01804188\n",
      "  -0.07785476]\n",
      " [ 0.38273243 -0.03424228  1.09634685 ...  0.0941923  -1.14761094\n",
      "  -0.35811408]\n",
      " [ 0.55596268  0.89247389 -0.42231482 ... -0.24679356 -1.07934317\n",
      "  -0.11422555]\n",
      " ...\n",
      " [-1.28277909 -0.17950901  0.27819164 ... -1.31869965 -0.22116722\n",
      "   0.41593528]\n",
      " [-1.23162889 -0.51221521  0.12511042 ...  0.84961987 -0.81843243\n",
      "   0.16746637]\n",
      " [-1.09316138 -0.74909675  1.11398219 ... -0.52799973 -0.65857377\n",
      "  -0.55711525]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.378907"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pychop\n",
    "from numpy import linalg\n",
    "import jax\n",
    "\n",
    "X_np = np.random.randn(500, 500) # NumPy array\n",
    "X_th = torch.Tensor(X_np) # Torch array\n",
    "X_jx = jax.numpy.asarray(X_np) # JAX array\n",
    "print(X_np)\n",
    "\n",
    "pychop.backend('numpy')\n",
    "pyq_f = pychop.Chopi(num_bits=8) # The larger the ``bits`` are, the more accurate of the reconstruction is \n",
    "X_q = pyq_f.quantize(X_np) # quant array -> integer\n",
    "X_inv = pyq_f.dequantize(X_q) # dequant array -> floating point values\n",
    "linalg.norm(X_inv - X_np)\n",
    "    \n",
    "\n",
    "pychop.backend('torch')\n",
    "pyq_f = pychop.Chopi(num_bits=8)\n",
    "X_q = pyq_f.quantize(X_th)  # quant array -> integer\n",
    "X_inv = pyq_f.dequantize(X_q) # dequant array -> floating point values\n",
    "linalg.norm(X_inv - X_np)\n",
    "\n",
    "\n",
    "pychop.backend('jax')\n",
    "pyq_f = pychop.Chopi(num_bits=8)\n",
    "X_q = pyq_f.quantize(X_jx) # quant array -> integer\n",
    "X_inv = pyq_f.dequantize(X_q) # dequant array -> floating point values \n",
    "linalg.norm(X_inv - X_jx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddc123-0b3e-425c-a927-dfb9b6b5dacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88d6db-4dbc-43e2-8425-de169de29c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
