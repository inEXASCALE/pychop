{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296dd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pychop as pychop\n",
    "from pychop import QuantizedLayer, Rounding\n",
    "from pychop.chop import chop\n",
    "from pychop import float_params\n",
    "from time import time\n",
    "from numpy import linalg\n",
    "import jax\n",
    "# from pychop.chop import chop\n",
    "# from pychop.quant import quant\n",
    "from time import time\n",
    "from scipy.io import savemat\n",
    "# np.set_printoptions(precision=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8e9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405235  0.40015721  0.97873798 ...  0.92918181  0.22941801\n",
      "   0.41440588]\n",
      " [ 0.30972382 -0.73745619 -1.53691988 ...  0.51687218 -0.03292069\n",
      "   1.29811143]\n",
      " [-0.20211703 -0.833231    1.73360025 ...  0.75309415 -0.58103281\n",
      "  -0.19837974]\n",
      " ...\n",
      " [ 1.07432182  1.188486    0.5092741  ...  0.07053449  0.59975911\n",
      "  -2.41029925]\n",
      " [ 0.32432475 -0.02337844  1.62873399 ... -0.16088168 -1.59772992\n",
      "   1.414703  ]\n",
      " [ 0.63460807  1.38090977  0.54829109 ...  0.30762729 -0.11078251\n",
      "   0.83859307]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X_np = np.random.randn(5000, 5000) # Numpy array\n",
    "X_th = torch.Tensor(X_np) # torch array\n",
    "X_jx = jax.numpy.asarray(X_np)\n",
    "print(X_np)\n",
    "\n",
    "#savemat(\"tests/verify.mat\", {\"X\":X_np})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8962a603-dbb8-4992-924c-4fd7dcbd3ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7641,  0.3097, -0.2021,  2.4700,  0.3300])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_th[0:5, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b51fba",
   "metadata": {},
   "source": [
    "### print unit-roundoff in machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618838ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>xmins</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>p</th>\n",
       "      <th>emins</th>\n",
       "      <th>emin</th>\n",
       "      <th>emax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q43</td>\n",
       "      <td>6.25e-02</td>\n",
       "      <td>1.95e-03</td>\n",
       "      <td>1.56e-02</td>\n",
       "      <td>2.40e+02</td>\n",
       "      <td>4</td>\n",
       "      <td>-9</td>\n",
       "      <td>-6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q52</td>\n",
       "      <td>1.25e-01</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>6.10e-05</td>\n",
       "      <td>5.73e+04</td>\n",
       "      <td>3</td>\n",
       "      <td>-16</td>\n",
       "      <td>-14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>3.91e-03</td>\n",
       "      <td>9.18e-41</td>\n",
       "      <td>1.18e-38</td>\n",
       "      <td>3.39e+38</td>\n",
       "      <td>8</td>\n",
       "      <td>-133</td>\n",
       "      <td>-126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>4.88e-04</td>\n",
       "      <td>5.96e-08</td>\n",
       "      <td>6.10e-05</td>\n",
       "      <td>6.55e+04</td>\n",
       "      <td>11</td>\n",
       "      <td>-24</td>\n",
       "      <td>-14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t</td>\n",
       "      <td>4.88e-04</td>\n",
       "      <td>1.15e-41</td>\n",
       "      <td>1.18e-38</td>\n",
       "      <td>3.40e+38</td>\n",
       "      <td>11</td>\n",
       "      <td>-136</td>\n",
       "      <td>-126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s</td>\n",
       "      <td>5.96e-08</td>\n",
       "      <td>1.40e-45</td>\n",
       "      <td>1.18e-38</td>\n",
       "      <td>3.40e+38</td>\n",
       "      <td>24</td>\n",
       "      <td>-149</td>\n",
       "      <td>-126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d</td>\n",
       "      <td>1.11e-16</td>\n",
       "      <td>4.94e-324</td>\n",
       "      <td>2.23e-308</td>\n",
       "      <td>1.80e+308</td>\n",
       "      <td>53</td>\n",
       "      <td>-1074</td>\n",
       "      <td>-1022</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>q</td>\n",
       "      <td>9.63e-35</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>inf</td>\n",
       "      <td>113</td>\n",
       "      <td>-16494</td>\n",
       "      <td>-16382</td>\n",
       "      <td>16383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                u      xmins       xmin       xmax    p    emins     emin  \\\n",
       "0  q43   6.25e-02   1.95e-03   1.56e-02   2.40e+02    4       -9       -6   \n",
       "1  q52   1.25e-01   1.53e-05   6.10e-05   5.73e+04    3      -16      -14   \n",
       "2    b   3.91e-03   9.18e-41   1.18e-38   3.39e+38    8     -133     -126   \n",
       "3    h   4.88e-04   5.96e-08   6.10e-05   6.55e+04   11      -24      -14   \n",
       "4    t   4.88e-04   1.15e-41   1.18e-38   3.40e+38   11     -136     -126   \n",
       "5    s   5.96e-08   1.40e-45   1.18e-38   3.40e+38   24     -149     -126   \n",
       "6    d   1.11e-16  4.94e-324  2.23e-308  1.80e+308   53    -1074    -1022   \n",
       "7    q   9.63e-35   0.00e+00   0.00e+00        inf  113   -16494   -16382   \n",
       "\n",
       "     emax  \n",
       "0       7  \n",
       "1      15  \n",
       "2     127  \n",
       "3      15  \n",
       "4     127  \n",
       "5     127  \n",
       "6    1023  \n",
       "7   16383  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e72fb9",
   "metadata": {},
   "source": [
    "### set backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9297600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NumPy backend.\n"
     ]
    }
   ],
   "source": [
    "# pychop.backend('torch')\n",
    "pychop.backend('numpy', 1) # print information, NumPy is the default option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417a000",
   "metadata": {},
   "source": [
    "### run chop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ade7038-b100-46ee-8f12-45147d0f2047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 2.028095006942749\n",
      "[ 1.76367188  0.30981445 -0.20214844  2.47070312  0.33007812  0.30200195\n",
      "  0.37133789  0.38720703 -1.93945312  0.56152344]\n"
     ]
    }
   ],
   "source": [
    "pyq_f = chop('h')\n",
    "st = time()\n",
    "X_bit = pyq_f(X_np)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56faf742-e8cf-4665-bb8a-eaf6f93f43de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 0.993048906326294\n",
      "tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301,  0.3020,  0.3713,  0.3872,\n",
      "        -1.9395,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = chop('h', rmode=1)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7def80e-0e97-415d-aad8-cb7c510a422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 0.7100889682769775\n",
      "tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301,  0.3022,  0.3713,  0.3875,\n",
      "        -1.9395,  0.5620])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = chop('h', rmode=2)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504c13ad-7b33-44a0-aa02-b043ad4ee304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 0.7768659591674805\n",
      "tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298,  0.3020,  0.3711,  0.3872,\n",
      "        -1.9404,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = chop('h', rmode=3)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e283b85-043e-46d6-b0f1-f442255681fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 0.8116700649261475\n",
      "tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298,  0.3020,  0.3711,  0.3872,\n",
      "        -1.9395,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = chop('h', rmode=4)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a9234-2b01-44bc-adf7-2a8daf6adc45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "145f815f-c59c-4c88-8f08-ea2ea49c01fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input values:       tensor([ 1.7641,  0.3097, -0.2021,  2.4700,  0.3300])\n",
      "PyTorch FP16:       tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n",
      "\n",
      "\n",
      "nearest     ,  Truth:    tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n",
      "nearest     ,  Emulated: tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n",
      "up          ,  Truth:    tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301])\n",
      "up          ,  Emulated: tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301])\n",
      "down        ,  Truth:    tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298])\n",
      "down        ,  Emulated: tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298])\n",
      "towards_zero,  Truth:    tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298])\n",
      "towards_zero,  Emulated: tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298])\n"
     ]
    }
   ],
   "source": [
    "values = torch.tensor([1.7641, 0.3097, -0.2021, 2.4700, 0.3300])\n",
    "\n",
    "# half precision simulator (5 exponent bits, 10 mantissa bits)\n",
    "fp16_sim = Rounding(5, 10)\n",
    "\n",
    "rounding_modes = [\"nearest\", \"up\", \"down\", \"towards_zero\", \n",
    "                 \"stochastic_equal\", \"stochastic_proportional\"]\n",
    "\n",
    "# Compare with PyTorch's native FP16\n",
    "fp16_native = values.to(dtype=torch.float16).to(dtype=torch.float32)\n",
    "\n",
    "print(\"Input values:      \", values)\n",
    "print(\"PyTorch FP16:      \", fp16_native)\n",
    "print()\n",
    "\n",
    "print()\n",
    "rounding_modes_num = [1, 2, 3, 4, \"stochastic_equal\", \"stochastic_proportional\"]\n",
    "\n",
    "for mode in rounding_modes_num[:4]:\n",
    "    pyq_f = chop('h', rmode=mode)\n",
    "    groud_truth = pyq_f(values)\n",
    "    emulated = fp16_sim.quantize(values, rounding_modes[mode-1])\n",
    "    assert np.array_equal(emulated, groud_truth), print(\"error rmode 3\")\n",
    "    \n",
    "    print(f\"{rounding_modes[mode-1]:12}, \", \"Truth:\", f\"   {emulated}\")\n",
    "    print(f\"{rounding_modes[mode-1]:12}, \", \"Emulated:\", f\"{groud_truth}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a1316f-6338-4064-bbeb-c0a247fa9702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original values: tensor([ 0.1000,  0.3000,  1.7000,  3.9000, -2.5000])\n",
      "nearest: tensor([ 0.1001,  0.3008,  1.7031,  3.9062, -2.5000])\n",
      "up: tensor([ 0.1001,  0.3008,  1.7031,  3.9062, -2.5000])\n",
      "down: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n",
      "towards_zero: tensor([ 0.0996,  0.2988,  1.6953,  3.8906, -2.5000])\n",
      "stochastic_equal: tensor([ 0.0996,  0.3008,  1.6953,  3.8906, -2.5000])\n",
      "stochastic_proportional: tensor([ 0.1001,  0.3008,  1.6953,  3.9062, -2.5000])\n",
      "\n",
      "Layer output shape: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "formats = {\n",
    "    \"fp32\": (8, 23),    # Standard IEEE 754 float32\n",
    "    \"fp16\": (5, 10),    # Standard IEEE 754 float16\n",
    "    \"bf16\": (8, 7),     # bfloat16\n",
    "    \"fp8\": (5, 2),      # Example 8-bit float\n",
    "}\n",
    "\n",
    "# Test different rounding modes\n",
    "rounding_modes = [\n",
    "    \"nearest\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"towards_zero\",\n",
    "    \"stochastic_equal\",\n",
    "    \"stochastic_proportional\"\n",
    "]\n",
    "\n",
    "# Create a sample tensor\n",
    "x = torch.tensor([0.1, 0.3, 1.7, 3.9, -2.5])\n",
    "\n",
    "# Test quantization\n",
    "mp = Rounding(*formats[\"bf16\"])\n",
    "\n",
    "print(\"Original values:\", x)\n",
    "for mode in rounding_modes:\n",
    "    result = mp.quantize(x, mode)\n",
    "    print(f\"{mode}:\", result)\n",
    "\n",
    "# Test with a layer\n",
    "layer = QuantizedLayer(4, 2, *formats[\"bf16\"], rounding_mode=\"nearest\")\n",
    "input_tensor = torch.randn(3, 4)\n",
    "output = layer(input_tensor)\n",
    "print(\"\\nLayer output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b33c5695-d12d-4c8f-9ae8-32762b70f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 0.9264817237854004\n",
      "tensor([ 1.7637,  0.3098, -0.2021,  2.4707,  0.3301])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = chop('h', rmode=1)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a90d1771-a080-4386-bfd5-0c86bd09db3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.0012319087982178\n",
      "tensor([ 1.7646,  0.3098, -0.2020,  2.4707,  0.3301])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = chop('h', rmode=2)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c37848fd-10fc-4789-b1cb-8e1e77ec315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.0078048706054688\n",
      "tensor([ 1.7637,  0.3096, -0.2021,  2.4688,  0.3298])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = chop('h', rmode=3)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db74eb8-dd68-4673-8b63-e55e426081ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Troch backend.\n",
      "runtime: 1.1233789920806885\n",
      "tensor([ 1.7637,  0.3096, -0.2020,  2.4688,  0.3298])\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('torch', 1) # print information\n",
    "pyq_f = chop('h', rmode=4)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_th)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01b59fd0-ed01-4ac7-98c2-0741e84f032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load JAX backend.\n",
      "runtime: 7.8559112548828125\n",
      "[[ 1.7636719   0.40014648  0.9785156  ...  0.9291992   0.22937012\n",
      "   0.41430664]\n",
      " [ 0.30981445 -0.7373047  -1.5371094  ...  0.51708984 -0.03292847\n",
      "   1.2978516 ]\n",
      " [-0.20214844 -0.8330078   1.7333984  ...  0.7529297  -0.5810547\n",
      "  -0.19836426]\n",
      " ...\n",
      " [ 1.0742188   1.1884766   0.50927734 ...  0.07055664  0.5996094\n",
      "  -2.4101562 ]\n",
      " [ 0.32421875 -0.02337646  1.6289062  ... -0.16088867 -1.5976562\n",
      "   1.4150391 ]\n",
      " [ 0.6347656   1.3808594   0.54833984 ...  0.3076172  -0.11077881\n",
      "   0.8383789 ]]\n"
     ]
    }
   ],
   "source": [
    "pychop.backend('jax', 1) # print information\n",
    "pyq_f = chop('h')\n",
    "st = time()\n",
    "X_bit = pyq_f(X_jx)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57b1a7c5-d1c8-4850-8dc4-a1af7b1417a3",
   "metadata": {},
   "source": [
    "pychop.backend('torch')\n",
    "pyq_f = chop('h', device='cuda')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_gpu = X_th.to(device)\n",
    "pyq_f(X_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79af559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22ecc758",
   "metadata": {},
   "source": [
    "### integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c29813b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.800703887228494"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('numpy')\n",
    "pyq_f = pychop.quant(bits=8)\n",
    "X_q = pyq_f(X_np)\n",
    "X_inv = pyq_f.dequant(X_q)\n",
    "linalg.norm(X_inv - X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef762b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.800703841249906"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('torch')\n",
    "pyq_f = pychop.quant(bits=8)\n",
    "X_q = pyq_f(X_th)\n",
    "X_inv = pyq_f.dequant(X_q)\n",
    "linalg.norm(X_inv - X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea235d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.7823"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pychop.backend('jax')\n",
    "pyq_f = pychop.quant(bits=8)\n",
    "X_q = pyq_f(X_jx)\n",
    "X_inv = pyq_f.dequant(X_q)\n",
    "linalg.norm(X_inv - X_jx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151a103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00497bc7",
   "metadata": {},
   "source": [
    "### fixed point quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2099b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.75  ,  0.375 ,  1.    , ...,  0.9375,  0.25  ,  0.4375],\n",
       "       [ 0.3125, -0.75  , -1.5625, ...,  0.5   , -0.0625,  1.3125],\n",
       "       [-0.1875, -0.8125,  1.75  , ...,  0.75  , -0.5625, -0.1875],\n",
       "       ...,\n",
       "       [ 1.0625,  1.1875,  0.5   , ...,  0.0625,  0.625 , -2.4375],\n",
       "       [ 0.3125, -0.    ,  1.625 , ..., -0.1875, -1.625 ,  1.4375],\n",
       "       [ 0.625 ,  1.375 ,  0.5625, ...,  0.3125, -0.125 ,  0.8125]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('numpy')\n",
    "pyq_f = pychop.fpoint()\n",
    "\n",
    "pyq_f(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a320530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7500,  0.3750,  1.0000,  ...,  0.9375,  0.2500,  0.4375],\n",
       "        [ 0.3125, -0.7500, -1.5625,  ...,  0.5000, -0.0625,  1.3125],\n",
       "        [-0.1875, -0.8125,  1.7500,  ...,  0.7500, -0.5625, -0.1875],\n",
       "        ...,\n",
       "        [ 1.0625,  1.1875,  0.5000,  ...,  0.0625,  0.6250, -2.4375],\n",
       "        [ 0.3125, -0.0000,  1.6250,  ..., -0.1875, -1.6250,  1.4375],\n",
       "        [ 0.6250,  1.3750,  0.5625,  ...,  0.3125, -0.1250,  0.8125]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('torch')\n",
    "pyq_f = pychop.fpoint()\n",
    "pyq_f(X_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f58d8820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.75  ,  0.375 ,  1.    , ...,  0.9375,  0.25  ,  0.4375],\n",
       "       [ 0.3125, -0.75  , -1.5625, ...,  0.5   , -0.0625,  1.3125],\n",
       "       [-0.1875, -0.8125,  1.75  , ...,  0.75  , -0.5625, -0.1875],\n",
       "       ...,\n",
       "       [ 1.0625,  1.1875,  0.5   , ...,  0.0625,  0.625 , -2.4375],\n",
       "       [ 0.3125, -0.    ,  1.625 , ..., -0.1875, -1.625 ,  1.4375],\n",
       "       [ 0.625 ,  1.375 ,  0.5625, ...,  0.3125, -0.125 ,  0.8125]],      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pychop.backend('jax')\n",
    "pyq_f = pychop.fpoint()\n",
    "pyq_f(X_jx)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b02be34-c7b5-462c-92b4-f977e746ad53",
   "metadata": {},
   "source": [
    "from pychop.bitchop import bitchop\n",
    "pychop.backend('numpy')\n",
    "\n",
    "pyq_f = bitchop(exp_bits=5, sig_bits=10, rmode=1, subnormal=True, random_state=42, device=\"cpu\", verbose=0)\n",
    "st = time()\n",
    "X_bit = pyq_f(X_np)\n",
    "print(\"runtime:\", time() - st)\n",
    "print(X_bit[:10, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31030621-0cd6-4a07-8376-1e1d9e3ebd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf31fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05eca45-ff22-4368-a68a-8fd4c6728f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
